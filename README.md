# ğŸ¤– Learning from Demonstration (LfD) for Robots

This repository contains the implementation of a **Learning from Demonstration (LfD)** pipeline for robots, developed as part of a research project exploring how robots can **learn new skills by observing human demonstrations** instead of being explicitly programmed.

The system integrates **ROS 2**, **Gazebo**, and **PyTorch** to enable **end-to-end imitation learning**, mapping **visual and proprioceptive inputs** to **robot control actions**.

---

## ğŸ§© Project Overview

**Learning from Demonstration (LfD)** is a core technique in robot learning that allows autonomous agents to acquire new behaviors from expert demonstrations.  
This project implements and compares multiple imitation learning approaches:

- **Behavior Cloning (BC)** â€“ supervised imitation using stateâ€“action pairs.  
- **Inverse Reinforcement Learning (IRL)** â€“ recovering the reward function driving expert actions.  
- **Generative Adversarial Imitation Learning (GAIL)** â€“ learning via adversarial expertâ€“learner interaction.

The objective is to evaluate how effectively robots can **generalize learned behaviors** to **unseen environments**, improving adaptability and collaboration in humanâ€“robot systems.

---

## âš™ï¸ System Architecture

Human Demonstration (Teleoperation / Simulation)
â”‚
â–¼
Data Collection (ROS 2)
â”‚
â–¼
Trajectory + Visual Feature Extraction
â”‚
â–¼
Policy Learning (PyTorch)
â”‚
â–¼
Policy Deployment (ROS 2 + Gazebo)
â”‚
â–¼
Evaluation & Generalization Tests


---

## ğŸ§  Key Components

| Component | Description |
|------------|-------------|
| **ROS 2 (Humble/Foxy)** | Middleware for robotic communication and control |
| **Gazebo / Ignition** | 3D simulator for collecting demonstrations and testing learned policies |
| **PyTorch** | Deep learning framework for training imitation models |
| **OpenAI Gym / RL Bench (optional)** | For standardized task environments |
| **Teleop Node** | Interface for human-controlled demonstrations |

---

## ğŸ§ª Features

âœ… End-to-end LfD pipeline (from demonstration to autonomous execution)  
âœ… Integration of ROS 2 nodes with PyTorch models  
âœ… Support for Behavior Cloning, IRL, and GAIL  
âœ… Real-time data collection from teleoperation or simulation  
âœ… Evaluation metrics: success rate, imitation accuracy, generalization  
âœ… Modular and reproducible design for research and extensions  

---

## ğŸ§° Installation

### Prerequisites
- **Ubuntu 22.04 / 24.04**
- **ROS 2 (Humble or newer)**
- **Gazebo / Ignition Fortress or Harmonic**
- **Python 3.10+**
- **PyTorch â‰¥ 2.0**
- **Colcon build tools**

### Setup Instructions
```bash
# Clone repository
git clone https://github.com/Samarthsri1608/LfD.git
cd LfD

# Setup workspace
mkdir -p ~/lfd_ws/src
mv * ~/lfd_ws/src/
cd ~/lfd_ws

# Install dependencies
rosdep install --from-paths src --ignore-src -r -y
pip install -r src/requirements.txt

# Build the workspace
colcon build
source install/setup.bash

```
---

## ğŸ® Usage
1. Run Gazebo Simulation
ros2 launch lfd_sim simulation.launch.py

2. Record Human Demonstrations
ros2 run lfd_demo record_demo --output demo_data/

3. Train Imitation Policy
python train_policy.py --method behavior_cloning --data demo_data/

4. Deploy Learned Policy
ros2 run lfd_policy execute_policy --model checkpoints/bc_model.pth


## Evaluation Metrics

Task Success Rate (SR) â€“ Percentage of successful task completions

Mean Squared Error (MSE) â€“ Between predicted and expert trajectories

Imitation Accuracy (IA) â€“ Similarity score between action distributions

Generalization Index (GI) â€“ Performance on unseen initial states

## Directory Structure
LfD/
â”œâ”€â”€ lfd_demo/                 # ROS 2 package for demonstration collection
â”œâ”€â”€ lfd_policy/               # ROS 2 package for policy deployment
â”œâ”€â”€ lfd_training/             # Training scripts for BC, IRL, GAIL
â”œâ”€â”€ models/                   # Pretrained models
â”œâ”€â”€ launch/                   # Simulation and execution launch files
â”œâ”€â”€ demo_data/                # Sample trajectories (optional)
â”œâ”€â”€ docs/                     # Research documentation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

## ğŸ§© Research Objectives

Develop a reproducible LfD pipeline in ROS 2 + Gazebo

Integrate deep imitation learning models in PyTorch

Quantitatively evaluate learned behaviors across tasks

Contribute an open-source framework for future LfD research

## ğŸ“š Citation

If you use this repository in your research, please cite:

@article{Samarth2025lfd,
  title   = {Learning from Demonstration for Robots: An End-to-End Imitation Learning Pipeline in ROS 2 and Gazebo},
  author  = {Samarth Srivastava},
  year    = {2025},
  journal = {Unpublished Research Project / GitHub Repository}
}

## ğŸ“œ License

This project is licensed under the MIT License â€” see the LICENSE file for details.

## ğŸ™Œ Acknowledgements

This project is inspired by:

OpenAIâ€™s Imitation Learning Benchmarks

Stanfordâ€™s CS 287: Advanced Robotics course materials

The ROS 2 + Gazebo simulation ecosystem

Researchers in LfD, IRL, and GAIL for foundational work in robot imitation learning